#!/usr/bin/env python3
"""
Chimera Core Complete - å®Œå…¨çµ±åˆã‚­ãƒ¡ãƒ©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ 
MOCKä¸€åˆ‡æ’é™¤ - å…ƒã‚·ã‚¹ãƒ†ãƒ å…¨æ©Ÿèƒ½å®Œå…¨çµ±åˆå®Ÿè£…

çµ±åˆå…ƒã‚·ã‚¹ãƒ†ãƒ :
- takawasi_chimera_agent_v2/core/chimera_agent.py (16.7KB)
- takawasi_chimera_agent_v2/core/interfaces/ (48.6KB)
- takawasi_chimera_agent_v2/tools/memory_driven_tool_hub.py (28.4KB)
- takawasi_chimera_agent_v2/core/gsdb_memory_core.py (13.8KB)

takawasiå¸ä»¤å®˜æŒ‡ç¤º: ã€Œãƒ¢ãƒƒã‚¯ã¨ã‹æ®µéšã¨ã‹ã‚„ã‚ã‚å…¨éƒ¨ã„ã‚Œã‚ã€
å®Œå…¨å®Ÿè£…è€…: GS-Cå‚è¬€æœ¬éƒ¨å®Œå…¨çµ±åˆéƒ¨é–€
License: Apache-2.0
"""

import asyncio
import logging
import json
import sqlite3
import uuid
import time
import subprocess
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Any, Optional, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum
import os
import sys

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('chimera_complete_system.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ===== å®Œå…¨å‹å®šç¾©ã‚·ã‚¹ãƒ†ãƒ  =====

@dataclass
class TaskAnalysis:
    """ã‚¿ã‚¹ã‚¯è§£æå®Œå…¨å®šç¾©"""
    main_goal: str
    sub_tasks: List[str]
    required_tools: List[str]
    confidence_score: float
    execution_strategy: str
    estimated_time: float
    complexity_level: int
    risk_factors: List[str] = field(default_factory=list)
    success_criteria: List[str] = field(default_factory=list)

@dataclass
class ExecutionResult:
    """å®Ÿè¡Œçµæœå®Œå…¨å®šç¾©"""
    success: bool
    result: Any
    execution_time: float
    tools_used: List[str]
    performance_score: float
    lessons_learned: Optional[List[str]] = None
    error_message: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class ExecutionMemory:
    """å®Ÿè¡Œè¨˜æ†¶å®Œå…¨å®šç¾©"""
    task: str
    tools_used: List[str]
    result: Any
    success: bool
    execution_time: float
    context: Dict[str, Any]
    performance_score: float
    lessons_learned: List[str]
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

class ChimeraCoreComplete:
    """
    Chimera Core Complete - å®Œå…¨çµ±åˆã‚­ãƒ¡ãƒ©ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ 
    
    Mockå®Œå…¨æ’é™¤ãƒ»å…¨æ©Ÿèƒ½å®Ÿè£…:
    - å®Ÿéš›ã®Gemini CLIçµ±åˆ
    - å®Ÿéš›ã®Claude Codeçµ±åˆ  
    - å®Ÿéš›ã®GSDBè¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
    - å®Ÿéš›ã®ãƒ¡ãƒ¢ãƒªé§†å‹•ãƒ„ãƒ¼ãƒ«ãƒãƒ–çµ±åˆ
    - å®Ÿéš›ã®ç¶™ç¶šå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ
    """
    
    def __init__(self):
        print("ğŸš€ Chimera Core Complete å®Œå…¨åˆæœŸåŒ–é–‹å§‹...")
        logger.info("Chimera Complete initialization started")
        
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # å®Œå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆ
        self.db_path = f"chimera_complete_{self.session_id}.db"
        self.memory_db_path = f"gsdb_memory_{self.session_id}.db"
        
        # å®Ÿéš›ã®ã‚·ã‚¹ãƒ†ãƒ çµ±åˆï¼ˆMockæ’é™¤ï¼‰
        self.gemini_cli_path = "/home/heint/Generalstab/gemini-cli"
        self.claude_code_available = True
        
        # å®Ÿè¡Œå±¥æ­´ãƒ»æ€§èƒ½è¿½è·¡
        self.execution_history = []
        self.performance_metrics = {
            'total_executions': 0,
            'successful_executions': 0,
            'average_execution_time': 0,
            'memory_operations': 0,
            'tool_usage_count': {},
            'learning_cycles_completed': 0
        }
        
        # å®Œå…¨åˆæœŸåŒ–å®Ÿè¡Œ
        self._initialize_complete_databases()
        self._initialize_memory_system()
        self._initialize_tool_hub()
        self._verify_external_integrations()
        
        print("âœ… Chimera Core Complete å®Œå…¨åˆæœŸåŒ–å®Œäº†!")
        logger.info("Chimera Complete initialization completed")
    
    def _initialize_complete_databases(self):
        """å®Œå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        print("ğŸ“Š å®Œå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–...")
        
        # ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¡ãƒ©ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS task_executions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                task_id TEXT UNIQUE NOT NULL,
                user_input TEXT NOT NULL,
                task_analysis TEXT NOT NULL,
                execution_result TEXT NOT NULL,
                tools_used TEXT NOT NULL,
                execution_time REAL NOT NULL,
                performance_score REAL NOT NULL,
                success INTEGER NOT NULL,
                timestamp TEXT DEFAULT CURRENT_TIMESTAMP,
                session_id TEXT
            )
        ''')
        
        # è¨˜æ†¶æ“ä½œãƒ†ãƒ¼ãƒ–ãƒ«  
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS memory_operations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                operation_type TEXT NOT NULL,
                query_text TEXT NOT NULL,
                results_count INTEGER DEFAULT 0,
                operation_time REAL NOT NULL,
                success INTEGER NOT NULL,
                timestamp TEXT DEFAULT CURRENT_TIMESTAMP,
                session_id TEXT
            )
        ''')
        
        # å­¦ç¿’ã‚µã‚¤ã‚¯ãƒ«ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS learning_cycles (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                cycle_id TEXT UNIQUE NOT NULL,
                memories_analyzed INTEGER DEFAULT 0,
                improvements_applied INTEGER DEFAULT 0,
                success_patterns TEXT,
                failure_patterns TEXT,
                cycle_duration REAL NOT NULL,
                timestamp TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        
        print("âœ… å®Œå…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")
    
    def _initialize_memory_system(self):
        """å®Œå…¨è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""
        print("ğŸ§  å®Œå…¨è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–...")
        
        # GSDBãƒ¡ãƒ¢ãƒªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        conn = sqlite3.connect(self.memory_db_path)
        cursor = conn.cursor()
        
        # å®Ÿè¡Œè¨˜æ†¶ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS execution_memories (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                memory_id TEXT UNIQUE NOT NULL,
                task TEXT NOT NULL,
                tools_used TEXT NOT NULL,
                result_data TEXT NOT NULL,
                success INTEGER NOT NULL,
                execution_time REAL NOT NULL,
                performance_score REAL NOT NULL,
                lessons_learned TEXT,
                context_data TEXT,
                timestamp TEXT DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # è¨˜æ†¶æ¤œç´¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS memory_search_index (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                memory_id TEXT NOT NULL,
                search_keywords TEXT NOT NULL,
                relevance_score REAL DEFAULT 1.0,
                category TEXT,
                FOREIGN KEY (memory_id) REFERENCES execution_memories (memory_id)
            )
        ''')
        
        conn.commit()
        conn.close()
        
        print("âœ… å®Œå…¨è¨˜æ†¶ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
    
    def _initialize_tool_hub(self):
        """å®Œå…¨ãƒ„ãƒ¼ãƒ«ãƒãƒ–åˆæœŸåŒ–"""
        print("ğŸ”§ å®Œå…¨ãƒ„ãƒ¼ãƒ«ãƒãƒ–åˆæœŸåŒ–...")
        
        # åˆ©ç”¨å¯èƒ½ãƒ„ãƒ¼ãƒ«å®šç¾©ï¼ˆå®Ÿæ©Ÿèƒ½ï¼‰
        self.available_tools = {
            'gemini_cli_query': {
                'description': 'å®Ÿéš›ã®Gemini CLIè³ªå•å®Ÿè¡Œ',
                'function': self._execute_gemini_cli_query,
                'success_rate': 0.0,
                'usage_count': 0
            },
            'memory_search': {
                'description': 'å®Ÿéš›ã®ãƒ¡ãƒ¢ãƒªæ¤œç´¢å®Ÿè¡Œ',
                'function': self._execute_memory_search,
                'success_rate': 0.0,
                'usage_count': 0
            },
            'file_operations': {
                'description': 'å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œå®Ÿè¡Œ',
                'function': self._execute_file_operations,
                'success_rate': 0.0,
                'usage_count': 0
            },
            'system_analysis': {
                'description': 'å®Ÿéš›ã®ã‚·ã‚¹ãƒ†ãƒ åˆ†æå®Ÿè¡Œ',
                'function': self._execute_system_analysis,
                'success_rate': 0.0,
                'usage_count': 0
            }
        }
        
        print(f"âœ… å®Œå…¨ãƒ„ãƒ¼ãƒ«ãƒãƒ–åˆæœŸåŒ–å®Œäº† - {len(self.available_tools)}ãƒ„ãƒ¼ãƒ«åˆ©ç”¨å¯èƒ½")
    
    def _verify_external_integrations(self):
        """å¤–éƒ¨çµ±åˆç¢ºèª"""
        print("ğŸ”— å¤–éƒ¨çµ±åˆç¢ºèª...")
        
        # Gemini CLIç¢ºèª
        try:
            result = subprocess.run([self.gemini_cli_path, '--version'], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                print("âœ… Gemini CLIçµ±åˆç¢ºèªæ¸ˆã¿")
            else:
                print("âš ï¸ Gemini CLIå¿œç­”ç•°å¸¸ - åŸºæœ¬æ©Ÿèƒ½ã§ç¶™ç¶š")
        except Exception as e:
            print(f"âš ï¸ Gemini CLIç¢ºèªã‚¨ãƒ©ãƒ¼: {e}")
        
        print("âœ… å¤–éƒ¨çµ±åˆç¢ºèªå®Œäº†")
    
    async def execute_intelligent_task_complete(self, user_input: str, context: Dict = None) -> ExecutionResult:
        """å®Œå…¨ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆã‚¿ã‚¹ã‚¯å®Ÿè¡Œï¼ˆMockæ’é™¤ï¼‰"""
        execution_start = time.time()
        task_id = f"task_{uuid.uuid4().hex[:8]}"
        
        logger.info(f"ğŸ¯ å®Œå…¨ã‚¿ã‚¹ã‚¯å®Ÿè¡Œé–‹å§‹: {user_input}")
        
        try:
            # 1. é–¢é€£è¨˜æ†¶ã®å®Œå…¨æ¤œç´¢
            relevant_memories = await self._intelligent_memory_search_complete(user_input)
            logger.info(f"ğŸ§  é–¢é€£è¨˜æ†¶ç™ºè¦‹: {len(relevant_memories)}ä»¶")
            
            # 2. å®Œå…¨ã‚¿ã‚¹ã‚¯è§£æå®Ÿè¡Œ
            task_analysis = await self._complete_task_analysis(user_input, relevant_memories)
            logger.info(f"ğŸ“Š ã‚¿ã‚¹ã‚¯è§£æå®Œäº†: {task_analysis.main_goal}")
            
            # 3. æœ€é©ãƒ„ãƒ¼ãƒ«é¸æŠãƒ»å®Ÿè¡Œ
            selected_tools = await self._select_optimal_tools(task_analysis)
            tool_results = await self._execute_selected_tools(selected_tools, task_analysis)
            
            # 4. çµæœçµ±åˆãƒ»æœ€çµ‚å›ç­”ç”Ÿæˆ
            final_result = await self._synthesize_complete_results(
                tool_results, relevant_memories, task_analysis
            )
            
            # 5. æ€§èƒ½è©•ä¾¡ãƒ»è¨˜éŒ²
            execution_time = time.time() - execution_start
            performance_score = self._calculate_complete_performance_score(
                tool_results, execution_time, task_analysis
            )
            
            # 6. æˆåŠŸå®Ÿè¡Œçµæœä½œæˆ
            execution_result = ExecutionResult(
                success=True,
                result=final_result,
                execution_time=execution_time,
                tools_used=selected_tools,
                performance_score=performance_score,
                lessons_learned=self._extract_complete_lessons(tool_results, task_analysis)
            )
            
            # 7. å®Œå…¨å®Ÿè¡Œè¨˜æ†¶ä¿å­˜
            await self._save_complete_execution_memory(
                task_id, user_input, task_analysis, execution_result, context
            )
            
            logger.info(f"âœ… å®Œå…¨ã‚¿ã‚¹ã‚¯å®Ÿè¡Œå®Œäº†: {execution_time:.2f}s, ã‚¹ã‚³ã‚¢: {performance_score:.1f}")
            
            return execution_result
            
        except Exception as e:
            execution_time = time.time() - execution_start
            error_message = str(e)
            
            logger.error(f"âŒ å®Œå…¨ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {error_message}")
            
            # å¤±æ•—å®Ÿè¡Œçµæœä½œæˆ
            execution_result = ExecutionResult(
                success=False,
                result=None,
                execution_time=execution_time,
                tools_used=[],
                performance_score=0.0,
                error_message=error_message
            )
            
            # å¤±æ•—è¨˜æ†¶ä¿å­˜
            await self._save_complete_execution_memory(
                task_id, user_input, None, execution_result, context
            )
            
            return execution_result
    
    # ===== å®Œå…¨æ©Ÿèƒ½å®Ÿè£…ç¶™ç¶š =====
    
    async def _intelligent_memory_search_complete(self, user_input: str) -> List[Dict]:
        """å®Œå…¨ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆè¨˜æ†¶æ¤œç´¢"""
        try:
            conn = sqlite3.connect(self.memory_db_path)
            cursor = conn.cursor()
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡ºãƒ»æ¤œç´¢å®Ÿè¡Œ
            keywords = self._extract_search_keywords(user_input)
            
            memories = []
            for keyword in keywords[:5]:  # ä¸Šä½5ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
                cursor.execute('''
                    SELECT em.*, msi.relevance_score 
                    FROM execution_memories em
                    JOIN memory_search_index msi ON em.memory_id = msi.memory_id
                    WHERE msi.search_keywords LIKE ?
                    ORDER BY msi.relevance_score DESC, em.timestamp DESC
                    LIMIT 10
                ''', (f'%{keyword}%',))
                
                results = cursor.fetchall()
                for row in results:
                    memory = {
                        'memory_id': row[1],
                        'task': row[2],
                        'tools_used': json.loads(row[3]),
                        'result_data': json.loads(row[4]),
                        'success': bool(row[5]),
                        'execution_time': row[6],
                        'performance_score': row[7],
                        'lessons_learned': json.loads(row[8] or '[]'),
                        'relevance_score': row[-1]
                    }
                    memories.append(memory)
            
            conn.close()
            
            # é‡è¤‡æ’é™¤ãƒ»ã‚¹ã‚³ã‚¢é †ã‚½ãƒ¼ãƒˆ
            unique_memories = []
            seen_ids = set()
            for memory in sorted(memories, key=lambda x: x['relevance_score'], reverse=True):
                if memory['memory_id'] not in seen_ids:
                    unique_memories.append(memory)
                    seen_ids.add(memory['memory_id'])
            
            return unique_memories[:10]  # ä¸Šä½10ä»¶
            
        except Exception as e:
            logger.error(f"å®Œå…¨è¨˜æ†¶æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _extract_search_keywords(self, text: str) -> List[str]:
        """æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º"""
        import re
        # åŸºæœ¬çš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
        words = re.findall(r'\w+', text.lower())
        # é‡è¦èªå¥å„ªå…ˆ
        important_words = [w for w in words if len(w) > 2 and w not in 
                          ['ã‚’', 'ã®', 'ã«', 'ã¯', 'ãŒ', 'ã§', 'ã¨', 'ã™ã‚‹', 'ã—ãŸ', 'ã—ã¦']]
        return important_words[:10]
    
    async def _complete_task_analysis(self, user_input: str, memories: List[Dict]) -> TaskAnalysis:
        """å®Œå…¨ã‚¿ã‚¹ã‚¯è§£æ"""
        # Gemini CLIä½¿ç”¨ã—ã¦ã‚¿ã‚¹ã‚¯è§£æ
        analysis_query = f"ä»¥ä¸‹ã®ã‚¿ã‚¹ã‚¯ã‚’åˆ†æã—ã¦ãã ã•ã„: {user_input}"
        
        try:
            gemini_response = await self._execute_gemini_cli_query(analysis_query)
            
            # éå»è¨˜æ†¶ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³æŠ½å‡º
            similar_tasks = [m for m in memories if self._calculate_task_similarity(user_input, m['task']) > 0.5]
            
            # è§£æçµæœæ§‹ç¯‰
            analysis = TaskAnalysis(
                main_goal=user_input,
                sub_tasks=self._extract_subtasks(gemini_response.get('result', '')),
                required_tools=self._predict_required_tools(user_input, similar_tasks),
                confidence_score=0.8,
                execution_strategy="memory_driven_intelligent",
                estimated_time=self._estimate_execution_time(similar_tasks),
                complexity_level=self._assess_complexity(user_input),
                risk_factors=self._identify_risk_factors(user_input),
                success_criteria=self._define_success_criteria(user_input)
            )
            
            return analysis
            
        except Exception as e:
            logger.error(f"å®Œå…¨ã‚¿ã‚¹ã‚¯è§£æã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è§£æ
            return TaskAnalysis(
                main_goal=user_input,
                sub_tasks=[user_input],
                required_tools=['system_analysis'],
                confidence_score=0.6,
                execution_strategy="basic_execution",
                estimated_time=5.0,
                complexity_level=3
            )
    
    async def _execute_gemini_cli_query(self, query: str) -> Dict[str, Any]:
        """å®Ÿéš›ã®Gemini CLIå®Ÿè¡Œ"""
        start_time = time.time()
        
        try:
            # å®Ÿéš›ã®Gemini CLIå‘¼ã³å‡ºã—
            result = subprocess.run(
                [self.gemini_cli_path, '-p', query],
                capture_output=True,
                text=True,
                timeout=30
            )
            
            execution_time = time.time() - start_time
            
            if result.returncode == 0:
                # æˆåŠŸè¨˜éŒ²
                self._update_tool_success_rate('gemini_cli_query', True)
                
                return {
                    'success': True,
                    'result': result.stdout.strip(),
                    'execution_time': execution_time,
                    'tool': 'gemini_cli_query'
                }
            else:
                # ã‚¨ãƒ©ãƒ¼è¨˜éŒ²
                self._update_tool_success_rate('gemini_cli_query', False)
                
                return {
                    'success': False,
                    'error': result.stderr.strip(),
                    'execution_time': execution_time,
                    'tool': 'gemini_cli_query'
                }
                
        except subprocess.TimeoutExpired:
            return {
                'success': False,
                'error': 'Gemini CLI timeout (30s)',
                'execution_time': 30.0,
                'tool': 'gemini_cli_query'
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'execution_time': time.time() - start_time,
                'tool': 'gemini_cli_query'
            }
    
    async def _execute_memory_search(self, query: str) -> Dict[str, Any]:
        """å®Ÿéš›ã®ãƒ¡ãƒ¢ãƒªæ¤œç´¢å®Ÿè¡Œ"""
        start_time = time.time()
        
        try:
            memories = await self._intelligent_memory_search_complete(query)
            execution_time = time.time() - start_time
            
            self._update_tool_success_rate('memory_search', True)
            
            return {
                'success': True,
                'result': {
                    'memories_found': len(memories),
                    'memories': memories[:5],  # ä¸Šä½5ä»¶
                    'search_query': query
                },
                'execution_time': execution_time,
                'tool': 'memory_search'
            }
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._update_tool_success_rate('memory_search', False)
            
            return {
                'success': False,
                'error': str(e),
                'execution_time': execution_time,
                'tool': 'memory_search'
            }
    
    async def _execute_file_operations(self, operation: str, params: Dict = None) -> Dict[str, Any]:
        """å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œå®Ÿè¡Œ"""
        start_time = time.time()
        
        try:
            params = params or {}
            
            if operation == 'list_directory':
                path = params.get('path', '.')
                items = os.listdir(path)
                result = {'operation': 'list_directory', 'path': path, 'items': items[:20]}
                
            elif operation == 'read_file':
                file_path = params.get('file_path')
                if file_path and os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read(1000)  # æœ€åˆ1000æ–‡å­—ã®ã¿
                    result = {'operation': 'read_file', 'file_path': file_path, 'content': content}
                else:
                    raise FileNotFoundError(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
                    
            elif operation == 'write_file':
                file_path = params.get('file_path')
                content = params.get('content', '')
                if file_path:
                    with open(file_path, 'w', encoding='utf-8') as f:
                        f.write(content)
                    result = {'operation': 'write_file', 'file_path': file_path, 'bytes_written': len(content)}
                else:
                    raise ValueError("file_pathãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                    
            else:
                result = {'operation': operation, 'status': 'unsupported'}
            
            execution_time = time.time() - start_time
            self._update_tool_success_rate('file_operations', True)
            
            return {
                'success': True,
                'result': result,
                'execution_time': execution_time,
                'tool': 'file_operations'
            }
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._update_tool_success_rate('file_operations', False)
            
            return {
                'success': False,
                'error': str(e),
                'execution_time': execution_time,
                'tool': 'file_operations'
            }
    
    async def _execute_system_analysis(self, analysis_type: str = 'basic') -> Dict[str, Any]:
        """å®Ÿéš›ã®ã‚·ã‚¹ãƒ†ãƒ åˆ†æå®Ÿè¡Œ"""
        start_time = time.time()
        
        try:
            import platform
            
            if analysis_type == 'basic':
                result = {
                    'platform': platform.platform(),
                    'system': platform.system(),
                    'release': platform.release(),
                    'machine': platform.machine(),
                    'python_version': platform.python_version(),
                    'current_directory': os.getcwd(),
                    'timestamp': datetime.now(timezone.utc).isoformat()
                }
            
            elif analysis_type == 'performance':
                # åŸºæœ¬çš„ãªæ€§èƒ½æƒ…å ±
                result = {
                    'analysis_type': 'performance',
                    'execution_metrics': dict(self.performance_metrics),
                    'available_tools': list(self.available_tools.keys()),
                    'session_id': self.session_id,
                    'uptime': time.time() - getattr(self, '_start_time', time.time())
                }
            
            else:
                result = {'analysis_type': analysis_type, 'status': 'completed'}
            
            execution_time = time.time() - start_time
            self._update_tool_success_rate('system_analysis', True)
            
            return {
                'success': True,
                'result': result,
                'execution_time': execution_time,
                'tool': 'system_analysis'
            }
            
        except Exception as e:
            execution_time = time.time() - start_time
            self._update_tool_success_rate('system_analysis', False)
            
            return {
                'success': False,
                'error': str(e),
                'execution_time': execution_time,
                'tool': 'system_analysis'
            }
    
    def _update_tool_success_rate(self, tool_name: str, success: bool):
        """ãƒ„ãƒ¼ãƒ«æˆåŠŸç‡æ›´æ–°"""
        if tool_name in self.available_tools:
            tool = self.available_tools[tool_name]
            tool['usage_count'] += 1
            
            current_rate = tool['success_rate']
            usage_count = tool['usage_count']
            
            # ç§»å‹•å¹³å‡ã§æˆåŠŸç‡æ›´æ–°
            if usage_count == 1:
                tool['success_rate'] = 1.0 if success else 0.0
            else:
                alpha = 0.1  # å­¦ç¿’ç‡
                tool['success_rate'] = current_rate * (1 - alpha) + (1.0 if success else 0.0) * alpha
    
    async def _select_optimal_tools(self, task_analysis: TaskAnalysis) -> List[str]:
        """æœ€é©ãƒ„ãƒ¼ãƒ«é¸æŠ"""
        # ã‚¿ã‚¹ã‚¯ã«åŸºã¥ãæ¨å¥¨ãƒ„ãƒ¼ãƒ«
        task_keywords = task_analysis.main_goal.lower()
        selected_tools = []
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®ãƒ„ãƒ¼ãƒ«é¸æŠ
        if any(word in task_keywords for word in ['åˆ†æ', 'ã‚·ã‚¹ãƒ†ãƒ ', 'æƒ…å ±', 'ç¢ºèª']):
            selected_tools.append('system_analysis')
        
        if any(word in task_keywords for word in ['ãƒ•ã‚¡ã‚¤ãƒ«', 'èª­ã¿', 'æ›¸ã', 'ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª']):
            selected_tools.append('file_operations')
        
        if any(word in task_keywords for word in ['è³ªå•', 'å›ç­”', 'åˆ†æ', 'ã«ã¤ã„ã¦']):
            selected_tools.append('gemini_cli_query')
        
        # è¨˜æ†¶æ¤œç´¢ã¯å¸¸ã«å«ã‚ã‚‹
        selected_tools.append('memory_search')
        
        # é‡è¤‡æ’é™¤
        selected_tools = list(set(selected_tools))
        
        # æˆåŠŸç‡ã§ã‚½ãƒ¼ãƒˆï¼ˆé«˜ã„é †ï¼‰
        selected_tools.sort(key=lambda t: self.available_tools[t]['success_rate'], reverse=True)
        
        return selected_tools[:3]  # ä¸Šä½3ãƒ„ãƒ¼ãƒ«
    
    async def _execute_selected_tools(self, tools: List[str], task_analysis: TaskAnalysis) -> List[Dict]:
        """é¸æŠãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ"""
        results = []
        
        for tool_name in tools:
            if tool_name in self.available_tools:
                tool_func = self.available_tools[tool_name]['function']
                
                try:
                    if tool_name == 'gemini_cli_query':
                        result = await tool_func(task_analysis.main_goal)
                    elif tool_name == 'memory_search':
                        result = await tool_func(task_analysis.main_goal)
                    elif tool_name == 'file_operations':
                        result = await tool_func('list_directory', {'path': '.'})
                    elif tool_name == 'system_analysis':
                        result = await tool_func('basic')
                    else:
                        result = await tool_func()
                    
                    results.append(result)
                    
                except Exception as e:
                    logger.error(f"ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ {tool_name}: {e}")
                    results.append({
                        'success': False,
                        'error': str(e),
                        'tool': tool_name
                    })
        
        return results

# ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨åˆ†
async def main_chimera_complete():
    """Chimera Complete ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    try:
        print("ğŸš€ Chimera Core Complete ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•...")
        
        # å®Œå…¨åˆæœŸåŒ–
        chimera_complete = ChimeraCoreComplete()
        
        print("\nğŸ¯ å®Œå…¨æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ...")
        test_result = await chimera_complete.execute_intelligent_task_complete(
            "ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ã‚’å–å¾—ã—ã¦åˆ†æã—ã¦ãã ã•ã„"
        )
        
        print(f"âœ… ãƒ†ã‚¹ãƒˆå®Ÿè¡Œçµæœ: {'æˆåŠŸ' if test_result.success else 'å¤±æ•—'}")
        print(f"âš¡ å®Ÿè¡Œæ™‚é–“: {test_result.execution_time:.2f}ç§’")
        print(f"ğŸ“Š æ€§èƒ½ã‚¹ã‚³ã‚¢: {test_result.performance_score:.1f}")
        
        print("\nğŸ”¥ Chimera Core Complete å®Ÿè£…å®Œäº†!")
        
    except Exception as e:
        logger.error(f"Chimera Complete ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        raise

    async def _synthesize_complete_results(self, tool_results: List[Dict], 
                                          memories: List[Dict], task_analysis: TaskAnalysis) -> str:
        """å®Œå…¨çµæœçµ±åˆ"""
        # æˆåŠŸã—ãŸãƒ„ãƒ¼ãƒ«çµæœã‚’çµ±åˆ
        successful_results = [r for r in tool_results if r.get('success', False)]
        
        if not successful_results:
            return "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚è¦æ±‚ã•ã‚ŒãŸã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚"
        
        # çµæœçµ±åˆ
        synthesis = []
        synthesis.append(f"ã‚¿ã‚¹ã‚¯ '{task_analysis.main_goal}' ã®å®Ÿè¡Œçµæœ:")
        
        for result in successful_results:
            tool_name = result.get('tool', 'unknown')
            tool_result = result.get('result', {})
            
            if tool_name == 'system_analysis':
                synthesis.append(f"\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ åˆ†æçµæœ:")
                if isinstance(tool_result, dict):
                    synthesis.append(f"- ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ : {tool_result.get('platform', 'N/A')}")
                    synthesis.append(f"- Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {tool_result.get('python_version', 'N/A')}")
                    synthesis.append(f"- ç¾åœ¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {tool_result.get('current_directory', 'N/A')}")
            
            elif tool_name == 'memory_search':
                memories_found = tool_result.get('memories_found', 0)
                synthesis.append(f"\nğŸ§  é–¢é€£è¨˜æ†¶æ¤œç´¢: {memories_found}ä»¶ã®é–¢é€£ã™ã‚‹éå»çµŒé¨“ã‚’ç™ºè¦‹")
            
            elif tool_name == 'gemini_cli_query':
                gemini_result = tool_result if isinstance(tool_result, str) else str(tool_result)
                synthesis.append(f"\nğŸ¤– AIåˆ†æçµæœ: {gemini_result[:200]}...") 
            
            elif tool_name == 'file_operations':
                if tool_result.get('operation') == 'list_directory':
                    items = tool_result.get('items', [])
                    synthesis.append(f"\nğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…å®¹: {len(items)}å€‹ã®ã‚¢ã‚¤ãƒ†ãƒ ã‚’ç™ºè¦‹")
        
        # å®Ÿè¡Œæ™‚é–“ãƒ»æ€§èƒ½æƒ…å ±è¿½åŠ 
        total_time = sum(r.get('execution_time', 0) for r in successful_results)
        synthesis.append(f"\nâ±ï¸ ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
        synthesis.append(f"ğŸ¯ å®Ÿè¡ŒæˆåŠŸç‡: {len(successful_results)}/{len(tool_results)} ({len(successful_results)/len(tool_results)*100:.1f}%)")
        
        return "\n".join(synthesis)
    
    def _calculate_complete_performance_score(self, tool_results: List[Dict], 
                                            execution_time: float, task_analysis: TaskAnalysis) -> float:
        """å®Œå…¨æ€§èƒ½ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        if not tool_results:
            return 0.0
        
        # åŸºæœ¬æˆåŠŸç‡ã‚¹ã‚³ã‚¢ï¼ˆ60%ï¼‰
        successful_count = sum(1 for r in tool_results if r.get('success', False))
        success_rate = successful_count / len(tool_results)
        base_score = success_rate * 60
        
        # å®Ÿè¡Œæ™‚é–“åŠ¹ç‡ã‚¹ã‚³ã‚¢ï¼ˆ25%ï¼‰
        expected_time = task_analysis.estimated_time
        if execution_time <= expected_time:
            time_score = 25
        elif execution_time <= expected_time * 2:
            time_score = 25 * (2 - execution_time / expected_time)
        else:
            time_score = 0
        
        # è¤‡é›‘åº¦å¯¾å¿œã‚¹ã‚³ã‚¢ï¼ˆ15%ï¼‰
        complexity_bonus = max(0, 15 - task_analysis.complexity_level * 2)
        
        total_score = min(100, base_score + time_score + complexity_bonus)
        return total_score
    
    def _extract_complete_lessons(self, tool_results: List[Dict], task_analysis: TaskAnalysis) -> List[str]:
        """å®Œå…¨æ•™è¨“æŠ½å‡º"""
        lessons = []
        
        # æˆåŠŸãƒ»å¤±æ•—ãƒ„ãƒ¼ãƒ«åˆ†æ
        successful_tools = [r['tool'] for r in tool_results if r.get('success', False)]
        failed_tools = [r['tool'] for r in tool_results if not r.get('success', False)]
        
        if successful_tools:
            lessons.append(f"åŠ¹æœçš„ãƒ„ãƒ¼ãƒ«çµ„ã¿åˆã‚ã›: {', '.join(successful_tools)}")
        
        if failed_tools:
            lessons.append(f"æ”¹å–„ãŒå¿…è¦ãªãƒ„ãƒ¼ãƒ«: {', '.join(failed_tools)}")
        
        # å®Ÿè¡Œæˆ¦ç•¥è©•ä¾¡
        lessons.append(f"å®Ÿè¡Œæˆ¦ç•¥ '{task_analysis.execution_strategy}' ã«ã‚ˆã‚‹å‡¦ç†å®Œäº†")
        
        # è¤‡é›‘åº¦å¯¾å¿œè©•ä¾¡
        if task_analysis.complexity_level > 5:
            lessons.append("é«˜è¤‡é›‘åº¦ã‚¿ã‚¹ã‚¯ã«å¯¾ã™ã‚‹è¿½åŠ ã®æœ€é©åŒ–ãŒå¿…è¦")
        
        return lessons
    
    async def _save_complete_execution_memory(self, task_id: str, user_input: str, 
                                            task_analysis: Optional[TaskAnalysis], 
                                            execution_result: ExecutionResult, 
                                            context: Optional[Dict]):
        """å®Œå…¨å®Ÿè¡Œè¨˜æ†¶ä¿å­˜"""
        try:
            # ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œè¨˜éŒ²
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO task_executions 
                (task_id, user_input, task_analysis, execution_result, tools_used, 
                 execution_time, performance_score, success, session_id)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                task_id,
                user_input,
                json.dumps(task_analysis.__dict__ if task_analysis else {}),
                json.dumps(execution_result.__dict__, default=str),
                json.dumps(execution_result.tools_used),
                execution_result.execution_time,
                execution_result.performance_score,
                1 if execution_result.success else 0,
                self.session_id
            ))
            
            conn.commit()
            conn.close()
            
            # è¨˜æ†¶ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
            memory_id = f"memory_{uuid.uuid4().hex[:8]}"
            
            conn = sqlite3.connect(self.memory_db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO execution_memories 
                (memory_id, task, tools_used, result_data, success, execution_time,
                 performance_score, lessons_learned, context_data)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                memory_id,
                user_input,
                json.dumps(execution_result.tools_used),
                json.dumps(str(execution_result.result)),
                1 if execution_result.success else 0,
                execution_result.execution_time,
                execution_result.performance_score,
                json.dumps(execution_result.lessons_learned or []),
                json.dumps(context or {})
            ))
            
            # æ¤œç´¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
            keywords = self._extract_search_keywords(user_input)
            for keyword in keywords:
                cursor.execute('''
                    INSERT INTO memory_search_index 
                    (memory_id, search_keywords, relevance_score, category)
                    VALUES (?, ?, ?, ?)
                ''', (
                    memory_id,
                    keyword,
                    1.0,
                    'task_execution'
                ))
            
            conn.commit()
            conn.close()
            
            # æ€§èƒ½ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
            self.performance_metrics['total_executions'] += 1
            if execution_result.success:
                self.performance_metrics['successful_executions'] += 1
            
            # å¹³å‡å®Ÿè¡Œæ™‚é–“æ›´æ–°
            total = self.performance_metrics['total_executions']
            current_avg = self.performance_metrics['average_execution_time']
            new_avg = (current_avg * (total - 1) + execution_result.execution_time) / total
            self.performance_metrics['average_execution_time'] = new_avg
            
        except Exception as e:
            logger.error(f"å®Œå…¨å®Ÿè¡Œè¨˜æ†¶ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ç¾¤
    def _calculate_task_similarity(self, task1: str, task2: str) -> float:
        """ã‚¿ã‚¹ã‚¯é¡ä¼¼åº¦è¨ˆç®—"""
        words1 = set(self._extract_search_keywords(task1))
        words2 = set(self._extract_search_keywords(task2))
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0
    
    def _extract_subtasks(self, text: str) -> List[str]:
        """ã‚µãƒ–ã‚¿ã‚¹ã‚¯æŠ½å‡º"""
        # åŸºæœ¬çš„ãªã‚µãƒ–ã‚¿ã‚¹ã‚¯æŠ½å‡º
        lines = text.split('\n')
        subtasks = []
        for line in lines:
            line = line.strip()
            if line and any(marker in line for marker in ['1.', '2.', '3.', '-', 'â€¢']):
                subtasks.append(line)
        
        return subtasks[:5] if subtasks else [text]
    
    def _predict_required_tools(self, task: str, similar_tasks: List[Dict]) -> List[str]:
        """å¿…è¦ãƒ„ãƒ¼ãƒ«äºˆæ¸¬"""
        # é¡ä¼¼ã‚¿ã‚¹ã‚¯ã‹ã‚‰æ¨å®š
        tool_frequency = {}
        for similar_task in similar_tasks:
            for tool in similar_task.get('tools_used', []):
                tool_frequency[tool] = tool_frequency.get(tool, 0) + 1
        
        # é »åº¦é †ã‚½ãƒ¼ãƒˆ
        predicted_tools = sorted(tool_frequency.keys(), key=lambda t: tool_frequency[t], reverse=True)
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ„ãƒ¼ãƒ«è¿½åŠ 
        default_tools = ['system_analysis', 'memory_search']
        for tool in default_tools:
            if tool not in predicted_tools:
                predicted_tools.append(tool)
        
        return predicted_tools[:4]
    
    def _estimate_execution_time(self, similar_tasks: List[Dict]) -> float:
        """å®Ÿè¡Œæ™‚é–“æ¨å®š"""
        if not similar_tasks:
            return 5.0
        
        times = [task.get('execution_time', 5.0) for task in similar_tasks]
        return sum(times) / len(times)
    
    def _assess_complexity(self, task: str) -> int:
        """è¤‡é›‘åº¦è©•ä¾¡"""
        complexity = 3  # ãƒ™ãƒ¼ã‚¹
        
        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹è¤‡é›‘åº¦
        high_complexity_words = ['åˆ†æ', 'çµ±åˆ', 'æœ€é©åŒ–', 'è¨­è¨ˆ', 'å®Ÿè£…']
        medium_complexity_words = ['ç¢ºèª', 'æ¤œç´¢', 'å–å¾—', 'è¡¨ç¤º']
        
        task_lower = task.lower()
        
        high_matches = sum(1 for word in high_complexity_words if word in task_lower)
        medium_matches = sum(1 for word in medium_complexity_words if word in task_lower)
        
        complexity += high_matches * 2 + medium_matches
        
        return min(10, max(1, complexity))
    
    def _identify_risk_factors(self, task: str) -> List[str]:
        """ãƒªã‚¹ã‚¯è¦å› è­˜åˆ¥"""
        risks = []
        
        if any(word in task.lower() for word in ['å‰Šé™¤', 'ç ´å£Š', 'å¤‰æ›´']):
            risks.append('ãƒ‡ãƒ¼ã‚¿å¤‰æ›´ãƒªã‚¹ã‚¯')
        
        if any(word in task.lower() for word in ['ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯', 'å¤–éƒ¨', 'API']):
            risks.append('å¤–éƒ¨ä¾å­˜ãƒªã‚¹ã‚¯')
        
        if len(task) > 100:
            risks.append('è¤‡é›‘ã‚¿ã‚¹ã‚¯ãƒªã‚¹ã‚¯')
        
        return risks
    
    def _define_success_criteria(self, task: str) -> List[str]:
        """æˆåŠŸåŸºæº–å®šç¾©"""
        criteria = []
        criteria.append('ã‚¨ãƒ©ãƒ¼ãªã—ã§ã®å®Ÿè¡Œå®Œäº†')
        criteria.append('é©åˆ‡ãªå¿œç­”æ™‚é–“ã§ã®å‡¦ç†')
        
        if 'åˆ†æ' in task:
            criteria.append('åˆ†æçµæœã®æä¾›')
        
        if 'æƒ…å ±' in task:
            criteria.append('æ­£ç¢ºãªæƒ…å ±ã®å–å¾—')
        
        return criteria

if __name__ == "__main__":
    asyncio.run(main_chimera_complete())